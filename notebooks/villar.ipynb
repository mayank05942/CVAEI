{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ../."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvaei\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from cvaei.examples.villar import Villar\n",
    "from cvaei.models.conv_cvae import CNN_CVAE\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villar = Villar()\n",
    "#mp.set_start_method('spawn')\n",
    "train_theta_norm, train_data_norm, theta_normalizer, data_normalizer, val_theta_norm, val_data_norm = villar.prepare_data(1000, scale = False)\n",
    "#observed_data = villar.observed_data()\n",
    "#villar.check_normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_norm[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villar.plot_observation(observed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villar.plot_observation(train_data_norm, num_samples =50)\n",
    "villar.plot_prior(train_theta_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "villar.plot_observation(val_data_norm, num_samples =2)\n",
    "villar.plot_prior(val_theta_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CVAE Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CNN_CVAE model\n",
    "input_dim = 15  # Example input dimension\n",
    "latent_dim = 200  # Example latent space dimension\n",
    "conditional_dim = 3  # Based on Nx3x200 conditional input\n",
    "encoder_hidden_dims = [200]  # Example hidden dimensions for the encoder\n",
    "sequence_length = 200  # Length of sequences in the conditional input\n",
    "conv_output_channels = [64, 32]  # Channels in each Conv1D layer for the decoder\n",
    "kernel_sizes = [3, 3]  # Kernel sizes for the Conv1D layers in the decoder\n",
    "output_channels = 3  # Matching the original conditional input's channels\n",
    "\n",
    "\n",
    "\n",
    "network = CNN_CVAE(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    conditional_dim=conditional_dim,\n",
    "    encoder_hidden_dims=encoder_hidden_dims,\n",
    "    decoder_hidden_dims=[],  # Assuming this is not used in the provided structure\n",
    "    sequence_length=sequence_length,\n",
    "    conv_output_channels=conv_output_channels,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    activation_fn= nn.LeakyReLU(0.1),\n",
    "    w_recon=0.1,\n",
    "    w_misfit=1.0,\n",
    "    kld=1.0\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(network.parameters(), lr=1e-3)\n",
    "\n",
    "train_dataset = TensorDataset(train_data_norm, train_theta_norm)\n",
    "val_dataset = TensorDataset(val_data_norm, val_theta_norm)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train_model(train_loader=train_loader,\n",
    "                    validation_loader= validation_loader,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=20,\n",
    "                    num_cycles = 1,\n",
    "                    theta_normalizer=theta_normalizer,\n",
    "                    data_normalizer=data_normalizer,\n",
    "                    \n",
    "                    patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = network.get_posterior(observed_data= observed_data, num_samples=10000)\n",
    "post = theta_normalizer.inverse_transform(post)\n",
    "villar.posterior_hist(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import dask\n",
    "#os.environ['PATH'] += \":/usr/local/cuda/bin/\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gillespy2\n",
    "from gillespy2 import SSACSolver\n",
    "from gillespy2 import Model, Species, Reaction, Parameter, RateRule, AssignmentRule, FunctionDefinition\n",
    "from gillespy2 import EventAssignment, EventTrigger, Event\n",
    "from gillespy2.core.events import *\n",
    "import sciope\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Vilar_Oscillator(gillespy2.Model):\n",
    "    def __init__(self, parameter_values=None):\n",
    "        gillespy2.Model.__init__(self, name=\"Vilar_Oscillator\")\n",
    "        self.volume = 1\n",
    "\n",
    "        # Parameters\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"alpha_a\", expression=50))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"alpha_a_prime\", expression=500))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"alpha_r\", expression=0.01))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"alpha_r_prime\", expression=50))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"beta_a\", expression=50))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"beta_r\", expression=5))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"delta_ma\", expression=10))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"delta_mr\", expression=0.5))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"delta_a\", expression=1))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"delta_r\", expression=0.2))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"gamma_a\", expression=1))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"gamma_r\", expression=1))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"gamma_c\", expression=2))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"theta_a\", expression=50))\n",
    "        self.add_parameter(gillespy2.Parameter(name=\"theta_r\", expression=100))\n",
    "\n",
    "        # Species\n",
    "        self.add_species(gillespy2.Species(name=\"Da\", initial_value=1, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"Da_prime\", initial_value=0, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"Ma\", initial_value=0, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"Dr\", initial_value=1, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"Dr_prime\", initial_value=0, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"Mr\", initial_value=0, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"C\", initial_value=10, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"A\", initial_value=10, mode=\"discrete\"))\n",
    "        self.add_species(gillespy2.Species(name=\"R\", initial_value=10, mode=\"discrete\"))\n",
    "\n",
    "        # Reactions\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r1\", reactants={'Da_prime': 1}, products={'Da': 1}, rate=self.listOfParameters[\"theta_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r2\", reactants={'Da': 1, 'A': 1}, products={'Da_prime': 1}, rate=self.listOfParameters[\"gamma_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r3\", reactants={'Dr_prime': 1}, products={'Dr': 1}, rate=self.listOfParameters[\"theta_r\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r4\", reactants={'Dr': 1, 'A': 1}, products={'Dr_prime': 1}, rate=self.listOfParameters[\"gamma_r\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r5\", reactants={'Da_prime': 1}, products={'Da_prime': 1, 'Ma': 1}, rate=self.listOfParameters[\"alpha_a_prime\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r6\", reactants={'Da': 1}, products={'Da': 1, 'Ma': 1}, rate=self.listOfParameters[\"alpha_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r7\", reactants={'Ma': 1}, products={}, rate=self.listOfParameters[\"delta_ma\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r8\", reactants={'Ma': 1}, products={'A': 1, 'Ma': 1}, rate=self.listOfParameters[\"beta_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r9\", reactants={'Da_prime': 1}, products={'Da_prime': 1, 'A': 1}, rate=self.listOfParameters[\"theta_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r10\", reactants={'Dr_prime': 1}, products={'Dr_prime': 1, 'A': 1}, rate=self.listOfParameters[\"theta_a\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r11\", reactants={'A': 1}, products={}, rate=self.listOfParameters[\"gamma_c\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r12\", reactants={'A': 1, 'R': 1}, products={'C': 1}, rate=self.listOfParameters[\"gamma_c\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r13\", reactants={'Dr_prime': 1}, products={'Dr_prime': 1, 'Mr': 1}, rate=self.listOfParameters[\"alpha_r_prime\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r14\", reactants={'Dr': 1}, products={'Dr': 1, 'Mr': 1}, rate=self.listOfParameters[\"alpha_r\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r15\", reactants={'Mr': 1}, products={}, rate=self.listOfParameters[\"delta_mr\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r16\", reactants={'Mr': 1}, products={'Mr': 1, 'R': 1}, rate=self.listOfParameters[\"beta_r\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r17\", reactants={'R': 1}, products={}, rate=self.listOfParameters[\"delta_r\"]))\n",
    "        self.add_reaction(gillespy2.Reaction(name=\"r18\", reactants={'C': 1}, products={'R': 1}, rate=self.listOfParameters[\"delta_a\"]))\n",
    "\n",
    "        # Timespan\n",
    "        self.timespan(np.linspace(0, 200, 200))\n",
    "        \n",
    "model = Vilar_Oscillator()\n",
    "solver = SSACSolver(model=model)\n",
    "parameter_names = ['alpha_a', 'alpha_a_prime', 'alpha_r', 'alpha_r_prime', \n",
    "                   'beta_a', 'beta_r', 'delta_ma', 'delta_mr', 'delta_a', \n",
    "                   'delta_r', 'gamma_a', 'gamma_r', 'gamma_c', 'theta_a', 'theta_r']\n",
    "\n",
    "# def simulator(params, model = model, transform = True):\n",
    "    \n",
    "#     params = params.ravel()\n",
    "#     res = model.run(\n",
    "#             solver = solver,\n",
    "#             timeout = 0.33,\n",
    "#             variables = {parameter_names[i] : params[i] for i in range(len(parameter_names))})\n",
    "    \n",
    "#     if res.rc == 33:\n",
    "#         return np.ones((1,3,200))\n",
    "#     if transform:\n",
    "#         sp_C = res['C']\n",
    "#         sp_A = res['A']\n",
    "#         sp_R = res['R']\n",
    "#         return np.vstack([sp_C, sp_A, sp_R])[np.newaxis,:,:]\n",
    " \n",
    "#     else:\n",
    "#         return res\n",
    "    \n",
    "def simulator(params, model = model):\n",
    "        \n",
    "        params_dict = {parameter_names[i]: param for i, param in enumerate(params)}\n",
    "        result = model.run(solver=solver, timeout=0.7, variables=params_dict)\n",
    "        \n",
    "        if result.rc == 33:  # Timeout or error\n",
    "            return np.full((3, 200), np.inf)\n",
    "        else:\n",
    "            return np.array([result[species] for species in ['C', 'A', 'R']])\n",
    "    \n",
    "dmin = [0,    100,    0,   20,   10,   1,    1,   0,   0,   0, 0.5,    0,   0,    0,   0]\n",
    "dmax = [80,   600,    4,   60,   60,   7,   12,   2,   3, 0.7, 2.5,   4,   3,   70,   300]\n",
    "true_param = np.asarray([50.0, 500.0, 0.01, 50.0, 50.0, 5.0, 10.0, 0.5, 1.0, 0.2, 1.0, 1.0, 2.0, 50.0, 100.0]).reshape(1,-1) \n",
    "\n",
    "def generate_data_parallel(N):\n",
    "    \"\"\" Returns the parameters and TS data using parallel processing\"\"\"\n",
    "    params = np.random.uniform(low=dmin, high=dmax, size=(N,15))\n",
    "    with mp.Pool(processes=96) as pool:\n",
    "        ts = pool.map(simulator, params)\n",
    "    ts = np.asarray(ts)\n",
    "    return ts,params\n",
    "\n",
    "train_ts, train_params = generate_data_parallel(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ones_samples(train_ts):\n",
    "    target = np.full((3, 200), np.inf)\n",
    "    count = 0\n",
    "    \n",
    "    for sample in train_ts:\n",
    "        # Check if any element in the sample is inf (np.inf)\n",
    "        if np.isinf(sample).any():\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "count_ones_samples(train_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Mayank Env",
   "language": "python",
   "name": "mayankenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
